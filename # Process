# Process
1. Get PDF documents
2. Convert PDF to text
3. Extract References
4. Hit Semantic scholar for abstract, 
4. Extract Files

# Set up Lucene 
http://www.gtlib.gatech.edu/pub/apache/lucene/java/8.6.2/lucene-8.6.2.zip
# Dependencies
pip install pyserini==0.9.4.0
pip install PyPDF2
pip install semanticscholar



# semantic scholar
import semanticscholar as sch
>>> paper = sch.paper('10.1093/mind/lix.236.433')
>>> paper.keys()
dict_keys(['abstract', 'arxivId', 'authors', 'citationVelocity', 'citations', 'doi',
'influentialCitationCount', 'paperId', 'references', 'title', 'topics', 'url', 'venue', 'year'])
>>> paper['title']
'Computing Machinery and Intelligence'
>>> for author in paper['authors']:
...     print(author['name'])
...     print(author['authorId'])


#
import PyPDF2  
    
# creating a pdf file object  
pdfFileObj = open('example.pdf', 'rb')  
    
# creating a pdf reader object  
pdfReader = PyPDF2.PdfFileReader(pdfFileObj)  
    
# printing number of pages in pdf file  
print(pdfReader.numPages)  
    
# creating a page object  
pageObj = pdfReader.getPage(0)  
    
# extracting text from page  
print(pageObj.extractText())  

# Code
from pyserini.search import SimpleSearcher

searcher = SimpleSearcher('indexes/index-robust04-20191213/')
hits = searcher.search('hubble space telescope')

# Print the first 10 hits:
for i in range(0, 10):
    print(f'{i+1:2} {hits[i].docid:15} {hits[i].score:.5f}')

# Grab the raw text:
hits[0].raw

# Grab the raw Lucene Document:
hits[0].lucene_document